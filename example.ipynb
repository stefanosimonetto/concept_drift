{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24ab47c",
   "metadata": {},
   "source": [
    "Embed Sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853808ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute BERT embeddings\n",
    "def compute_bert_embedding(text):\n",
    "    \"\"\"\n",
    "    Compute BERT embedding for a given text.\n",
    "    Returns the mean-pooled embedding as a list.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value for key, value in inputs.items()}  # Move inputs to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        embedding = last_hidden_state.mean(dim=1).squeeze().cpu().tolist()  # Mean pooling\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def add_embeddings_to_labels(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Add BERT embeddings\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "    with open(input_file, \"rb\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # note that this is a PoC, but the complete dataset should comprize of all the CVEs and not just the first 1000\n",
    "    for entry in tqdm(data[:1000]):\n",
    "        if entry[\"cwe_class\"] not in {\"None\", \"CWE-noinfo\", \"CWE-Other\"}:  \n",
    "            entry[\"embedding\"] = compute_bert_embedding(entry[\"Description\"])\n",
    "\n",
    "    # Save updated data to a new file\n",
    "    with open(output_file, \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "    print(f\"Embeddings added and saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20301cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:26<00:00, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings added and saved to: cve_extracted_data2023_with_embeddings.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Input and Output Paths\n",
    "input_file = \"cve_extracted_data2023.json\"  # Path to the existing output JSON\n",
    "output_file = \"cve_extracted_data2023_with_embeddings.pickle\"  # Path to save the updated JSON\n",
    "\n",
    "print(\"Loading BERT model...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "add_embeddings_to_labels(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bfb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63db6c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CVE ID': 'CVE-2023-0001', 'Description': 'An information exposure vulnerability in the Palo Alto Networks Cortex XDR agent on Windows devices allows a local system administrator to disclose the admin password for the agent in cleartext, which bad actors can then use to execute privileged cytool commands that disable or uninstall the agent.', 'CWE': ['CWE-319'], 'cwe_class': '311', 'embedding': [-0.4415055215358734, 0.01594029739499092, 0.04627702385187149, 0.03500800579786301, 0.5448458790779114, -0.13969023525714874, 0.17242665588855743, 0.39190492033958435, 0.17194750905036926, -0.05938902124762535, -0.2591797709465027, -0.15562838315963745, -0.29512882232666016, 0.3031870424747467, -0.08647973090410233, 0.1043558418750763, 0.17719487845897675, 0.3072386384010315, -0.2042432725429535, -0.02973429299890995, 0.030058149248361588, -0.046129003167152405, -0.2965058386325836, 0.3241639733314514, 0.5221453309059143, -0.11155488342046738, -0.06877804547548294, 0.1445492058992386, -0.5345452427864075, 0.007514984346926212, 0.12919928133487701, 0.13155265152454376, -0.07702187448740005, -0.35957467555999756, -0.2222198098897934, 0.20897610485553741, -0.17121820151805878, -0.19963476061820984, -0.15106196701526642, 0.25016072392463684, -0.7585512399673462, -0.4018254578113556, 0.04642681032419205, 0.10668990015983582, 0.21300888061523438, -0.14899753034114838, 0.20352493226528168, 0.06722882390022278, 0.04372624680399895, -0.0855463519692421, -1.0249861478805542, 0.4724867641925812, -0.23928874731063843, 0.011796355247497559, 0.4502774178981781, 0.2969023585319519, 0.25437119603157043, -0.7991603016853333, 0.2387775480747223, -0.1709866225719452, -0.05096927657723427, -0.14320822060108185, 0.09956412017345428, -0.1397029310464859, -0.03535376116633415, 0.2391418069601059, 0.12090334296226501, 0.30951783061027527, -0.8812100887298584, -0.20550285279750824, -0.2510661780834198, -0.07611320912837982, -0.3610638976097107, -0.2908048927783966, -0.13645893335342407, 0.15051695704460144, -0.24964971840381622, 0.16685083508491516, -0.023870956152677536, 0.15514948964118958, -0.19111503660678864, 0.46841347217559814, 0.07172746956348419, 0.23296289145946503, 0.2976728081703186, -0.24373449385166168, -0.013014132156968117, 0.3143337666988373, -0.3964875638484955, 0.4932178556919098, -0.21686531603336334, 0.08732976764440536, 0.1109248623251915, 0.024166634306311607, -0.01079556904733181, 0.3045295476913452, -0.030261842533946037, 0.025943083688616753, 0.09054883569478989, 0.5243019461631775, 0.14168871939182281, -0.22310470044612885, -0.04606154188513756, 0.15134309232234955, -0.4645894169807434, -0.08479680120944977, -0.07120414823293686, 0.2863369584083557, -0.22277094423770905, 0.3563036620616913, 0.35640886425971985, 0.05948073789477348, -0.12246610224246979, -0.35774004459381104, -0.2634454071521759, -0.14988301694393158, -0.05840250477194786, -0.08686339110136032, 0.4649193584918976, -0.2722965478897095, 0.4750082790851593, 0.5685480237007141, 0.10815568268299103, 0.8994277715682983, -0.1526375710964203, -0.20741967856884003, -0.05068065971136093, 0.3775973320007324, 0.3741042912006378, -0.27668890357017517, -0.041918329894542694, 0.5857653021812439, 0.4334855377674103, 0.03502368927001953, -0.3092491030693054, 0.12273761630058289, -0.10883612185716629, -0.2176804542541504, -0.26356393098831177, -0.2714683711528778, 0.03703420236706734, -0.36457088589668274, 0.11753060668706894, 0.4165270924568176, 0.3473019599914551, 0.33785903453826904, 0.018996838480234146, -0.12226184457540512, -0.09451138228178024, 0.6200248003005981, 0.11052386462688446, 0.22646597027778625, -0.18544435501098633, 0.04860119894146919, -0.04916872829198837, 0.13530714809894562, 0.07573733478784561, -0.032186251133680344, -0.10371521860361099, 0.07428224384784698, 0.6625199913978577, 0.17403864860534668, -0.4985944926738739, -0.02087065763771534, 0.16398963332176208, -0.12119210511445999, -0.007054436020553112, 0.29471495747566223, 0.1649494767189026, 0.03515266254544258, -0.09699489176273346, -0.06930695474147797, 0.4789023697376251, -0.01602688990533352, 0.004263877868652344, 0.14630036056041718, 0.067605160176754, -0.09805559366941452, 0.5570358633995056, 0.10076897591352463, -0.8641968965530396, 0.2779847979545593, 0.0996680036187172, 0.2452506124973297, 0.003363696625456214, 0.11971130967140198, 0.3795122504234314, -0.4331728219985962, 0.054443057626485825, -0.25739631056785583, -0.4190755784511566, -0.4806828200817108, -0.4520341455936432, 0.029719799757003784, 0.30422481894493103, -0.39133206009864807, -0.32020753622055054, 0.16107375919818878, -0.42484837770462036, -0.024289807304739952, 0.46532025933265686, -0.17114487290382385, 0.024033430963754654, -0.2531853914260864, 0.04185674339532852, -0.3727167844772339, 0.11907490342855453, -0.4345196783542633, -0.5225169062614441, 0.14489684998989105, -0.3646814227104187, 0.24191851913928986, -0.3077893555164337, 0.17681993544101715, 0.2853541076183319, 0.33611229062080383, -0.3766518235206604, -0.10790763795375824, 0.13257893919944763, 0.03501063212752342, -0.013794664293527603, -0.20531773567199707, -0.44957810640335083, 0.5391719937324524, -0.5270955562591553, 1.1275311708450317, -0.09874432533979416, -0.06946534663438797, 0.5669605135917664, 0.4492968022823334, 0.0006564984796568751, -0.22566772997379303, 0.033281195908784866, -0.4034093916416168, -0.10190548747777939, 0.059016622602939606, -0.16112028062343597, -0.04562101140618324, 0.06822339445352554, -0.09577202051877975, -0.16425468027591705, 0.6001843214035034, 0.2988753020763397, 0.07756692916154861, 0.042895808815956116, -0.15417881309986115, -0.19343717396259308, 0.06588605046272278, -0.09923805296421051, -0.04276750609278679, -0.35069578886032104, -0.06728425621986389, -0.3385673463344574, -0.5029367208480835, 0.1579028069972992, -0.10839729011058807, -0.2601475715637207, -0.044952210038900375, -0.4217940866947174, 0.2793218493461609, 0.07844893634319305, 0.31839820742607117, -0.15112195909023285, 0.23755058646202087, -0.03117862343788147, -1.0831471681594849, 0.13979288935661316, 0.48555105924606323, 0.46418526768684387, -0.21739056706428528, -0.16023559868335724, -0.4179404675960541, -0.08711760491132736, 0.3832891583442688, -0.25987306237220764, -0.306762158870697, 0.1070040836930275, 0.49461787939071655, 0.21824680268764496, -0.21537451446056366, -0.0008495370275340974, 0.48677095770835876, -0.20866364240646362, 0.2888403534889221, -0.01336774043738842, -0.30412784218788147, 0.030444692820310593, -0.07215500622987747, -0.6121172308921814, -0.21252460777759552, -0.33343207836151123, 0.1625274270772934, -0.41740792989730835, 0.33271142840385437, -0.013476913794875145, 0.3472917973995209, 0.35418838262557983, 0.5749826431274414, 0.4116782546043396, -0.22238901257514954, -0.1603413075208664, -0.13458067178726196, -0.14169098436832428, 0.05201614648103714, -0.5898566842079163, -0.07244307547807693, -0.2002352923154831, -0.27826637029647827, -3.8398895263671875, 0.10356520861387253, 0.2800752818584442, -0.2978726625442505, 0.2873705327510834, -0.1656208038330078, 0.11510664969682693, -0.1758364588022232, 0.022475004196166992, 0.4463900625705719, -0.004424123093485832, -0.24243102967739105, 0.23752950131893158, 0.08359522372484207, -0.06281813234090805, 0.16287392377853394, 0.08114488422870636, -0.4340910315513611, -0.05077485367655754, -0.048027195036411285, -0.44485557079315186, -0.4766174852848053, 0.14107435941696167, -0.08822919428348541, -0.08636797219514847, 0.10410957038402557, -0.09801711142063141, -0.4056543707847595, 0.0761578232049942, -0.3395620882511139, -0.005438025575131178, -0.20571456849575043, 0.19404830038547516, 0.7153509855270386, -0.024685828015208244, 0.0632067322731018, 0.08308408409357071, -0.19108107686042786, -0.4743901491165161, -0.41070806980133057, 0.30741968750953674, -0.13660429418087006, 0.04307086020708084, -0.19114001095294952, 0.5282025933265686, -0.19127537310123444, 0.04881115257740021, -0.05433939769864082, 0.4256526827812195, 0.16836358606815338, -0.19578050076961517, -0.0017910560127347708, -0.507233738899231, 0.050001781433820724, 0.02304685115814209, -0.21443291008472443, 0.1386338323354721, 0.5581951141357422, -0.4633609652519226, 0.22355669736862183, 0.23261141777038574, -0.3490677773952484, -0.23950853943824768, -0.3023080825805664, -0.01518626231700182, -0.39810407161712646, -0.7544558048248291, -0.13581988215446472, 0.1681770235300064, 0.09053327888250351, -0.17413942515850067, 0.3829907774925232, -0.2509339451789856, -0.837664783000946, 0.1108059510588646, -0.5359448194503784, 0.04007228463888168, -0.37067553400993347, 0.01707308553159237, -0.2835281193256378, -0.2756742835044861, -0.16070839762687683, 0.20631006360054016, -0.23392371833324432, -0.146563321352005, -0.37212735414505005, 0.21961373090744019, 0.030518902465701103, 0.032219547778367996, -0.3269829750061035, 0.46337005496025085, 0.0895674079656601, 0.29831045866012573, 0.35664650797843933, 0.11779400706291199, 0.22925908863544464, 0.4304526150226593, -0.08433931320905685, 0.09609329700469971, -0.04190724715590477, 0.20576371252536774, -0.22255107760429382, 0.4832155108451843, -0.7328421473503113, -0.1033497080206871, 0.37066352367401123, -0.41365358233451843, -0.19345729053020477, 0.28798678517341614, 0.18161052465438843, -0.2995930314064026, -0.23036479949951172, 0.3811242878437042, -0.7567960023880005, -0.26830777525901794, 0.04801613464951515, 0.40358561277389526, 0.8756547570228577, 0.2237474024295807, -0.4113765060901642, -0.2821981608867645, 0.5949231386184692, -0.0658358708024025, -0.2426004707813263, -0.581122100353241, -0.20296421647071838, -0.20816665887832642, 0.22089719772338867, 0.19211870431900024, -0.283720463514328, -0.17064565420150757, -0.09481789916753769, 0.022809423506259918, 0.12255239486694336, 0.3728920817375183, -0.2032288759946823, -0.08780433237552643, 0.01046690158545971, -0.1455620676279068, -0.005518381018191576, -0.15888075530529022, 0.11873926967382431, 0.11562972515821457, -0.07073978334665298, 0.024184290319681168, -0.010134251788258553, 0.1112421378493309, -0.2521747946739197, 0.07345899939537048, -0.06620261073112488, -0.4969874322414398, -0.13343460857868195, 0.07193358987569809, 0.013918399810791016, 0.041884057223796844, 0.24601611495018005, 0.17530201375484467, -0.2803276777267456, -0.030242305248975754, -0.3333680331707001, 0.33963853120803833, 0.1521201878786087, 0.12008968740701675, 0.12546156346797943, -0.0748615562915802, 0.1977599710226059, -0.27472084760665894, -0.3691003918647766, -0.12838628888130188, 0.12690286338329315, -0.6149347424507141, -0.2583194971084595, 0.298211008310318, -0.05066295340657234, 0.2346704751253128, 0.4857328534126282, 0.1756785660982132, -0.033068254590034485, 0.26745977997779846, 0.4470110535621643, 0.2918427884578705, -0.021661873906850815, -0.38514524698257446, -0.4018990695476532, 0.2340060919523239, -0.16598612070083618, -0.01569977216422558, 0.08364042639732361, 0.010314089246094227, -0.016349757090210915, -0.4964027404785156, 0.5571262836456299, -0.18565163016319275, -0.20005390048027039, -0.12600663304328918, -0.18922081589698792, 0.23100420832633972, 0.15265952050685883, 0.10046996921300888, -0.025367943570017815, 0.35501396656036377, 0.1253301054239273, -0.6028144955635071, -0.06414684653282166, -0.18734166026115417, -0.13347196578979492, 0.10481075942516327, 0.13358312845230103, 0.12695863842964172, 0.041457366198301315, -0.17422980070114136, -0.12008459120988846, -0.4389958381652832, -0.44395914673805237, 0.5591691732406616, -0.2206811159849167, 0.031587302684783936, -0.25554561614990234, -0.3494463562965393, 0.1980256289243698, -0.6031964421272278, 0.06180761009454727, 0.2212161272764206, 0.6064053177833557, -0.251577764749527, -0.22340713441371918, 0.17635774612426758, -0.14187116920948029, -0.07638612389564514, 0.06642845273017883, 0.2591847777366638, -0.7480090260505676, 0.19384518265724182, 0.025899769738316536, -0.10737427324056625, -0.41728147864341736, -0.13928881287574768, -0.4765962064266205, -0.08890890330076218, -0.07803740352392197, -0.3898293375968933, 0.14890705049037933, -0.43675777316093445, -0.02673957124352455, 0.2870292663574219, -0.011099121533334255, -0.38895148038864136, 0.3652346432209015, -0.40894943475723267, 0.06222781166434288, 0.09487292915582657, 0.14130276441574097, -0.0659158006310463, 0.14875391125679016, 0.06450517475605011, -0.3946753740310669, -0.3828497529029846, -0.4249165952205658, -0.5547651052474976, -0.046893052756786346, 0.18185217678546906, -0.43006613850593567, 0.4465261995792389, 0.29521116614341736, 0.21646009385585785, 0.0034806907642632723, 0.36850985884666443, 0.19345228374004364, 0.18887300789356232, -0.32757312059402466, 0.21011237800121307, -0.45823028683662415, 0.27974578738212585, 0.3244641423225403, -0.20884130895137787, -0.02550634555518627, 0.27128690481185913, -0.41713109612464905, 0.18049350380897522, -0.501513659954071, -0.3307899236679077, -0.1906367689371109, -0.0868201032280922, -0.18325142562389374, 0.11987631767988205, -0.5646151900291443, 0.14462372660636902, -0.05073581263422966, 0.06834449619054794, -0.4498857855796814, -0.0724426805973053, 0.32975661754608154, 0.2792375981807709, -0.05196237191557884, -0.5350411534309387, 0.15466968715190887, 0.3498637080192566, 0.09658472239971161, -0.046616215258836746, 0.1385236233472824, -0.20303329825401306, 0.284662127494812, 0.6023884415626526, 0.16533245146274567, -0.08989588916301727, 0.17034906148910522, 0.20868425071239471, -0.6078758239746094, -0.569720447063446, -0.23409970104694366, -0.24317818880081177, -0.3519841432571411, 0.46207454800605774, 0.18649114668369293, -0.6302897334098816, -0.4088951051235199, -0.027232205495238304, 0.06070629507303238, -0.020187921822071075, -0.07530654966831207, 0.030859844759106636, 0.0905991643667221, 0.3592594265937805, 0.1395493894815445, 0.5049901008605957, 0.5164356827735901, 0.0738290473818779, -0.3452635109424591, -0.08386373519897461, 0.1521843820810318, -0.029686791822314262, 0.02412111684679985, -0.08926095813512802, 0.31813761591911316, 0.02234049327671528, -0.21667222678661346, 0.1706525683403015, -0.10620269924402237, -0.36663761734962463, -0.034516509622335434, 0.29379284381866455, 0.11641819030046463, 0.24551723897457123, 0.22060874104499817, -0.05537617951631546, 0.38162314891815186, 0.3765885531902313, 0.4765421748161316, 0.4798808693885803, 0.6430320739746094, 0.2402372509241104, 0.10729029774665833, 0.020625969395041466, 0.12259174138307571, 0.18635623157024384, 0.29708608984947205, 0.33526551723480225, 0.37946054339408875, -0.006342063192278147, 0.4506116807460785, 0.21229533851146698, -0.08567675203084946, 0.3492816090583801, -0.7117082476615906, -0.06299527734518051, 0.05072764679789543, 0.3113845884799957, -0.18138685822486877, -0.22380046546459198, -0.19210505485534668, 0.011119725182652473, 0.274313747882843, -0.052731260657310486, -0.22409887611865997, 0.13611651957035065, 0.16516444087028503, 0.2765127122402191, 0.0040625291876494884, -0.3698544204235077, -0.1441185027360916, -0.1618763953447342, 0.0213084165006876, -0.2136184424161911, -0.4158981442451477, -0.5737696886062622, -0.09043213725090027, -0.04059327393770218, -0.09075628966093063, -0.01700419932603836, -0.586352527141571, 0.04359772056341171, -0.04175339639186859, 0.4446524381637573, -0.23814477026462555, 0.17312075197696686, 0.04015371948480606, 0.018898192793130875, 0.33805206418037415, 0.5824617743492126, 0.30706706643104553, 0.2892835736274719, -0.18622088432312012, -0.05153301730751991, 0.11929016560316086, -0.10074973851442337, 0.29310402274131775, 0.037343185395002365, 0.20012728869915009, -0.5436770915985107, 0.05814353749155998, 0.5578766465187073, 0.3211922347545624, -0.5819630026817322, -0.3504835069179535, -0.03409985825419426, 0.24868856370449066, 0.4160093665122986, 0.3758488893508911, -0.3143244981765747, 0.14518752694129944, -0.29214730858802795, -0.19533713161945343, 0.4673984944820404, -0.134121835231781, 0.012855203822255135, 0.4329001307487488, 0.7211934328079224, 0.3613859713077545, 0.10660996288061142, 0.030916361138224602, -0.07010768353939056, 0.13188691437244415, 0.36931878328323364, 0.35396236181259155, -0.3272290825843811, -0.4142410159111023, -0.22975526750087738, 0.545595109462738, -0.23650100827217102, 0.009275865741074085, -0.13773320615291595, 0.025749100372195244, 0.41756948828697205, -0.14470425248146057, 0.2808785140514374, -0.20309801399707794, -0.1863100677728653, -0.3485729992389679, -0.18845586478710175, -0.33659183979034424, 0.0674171969294548, -0.0899578332901001, -0.1550006866455078, -0.39136913418769836, 0.012484597973525524, 0.5004953742027283, 0.21920156478881836, -0.271741658449173, -0.21246464550495148, 0.519905686378479]}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])  # Print the first entry to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2951ba8",
   "metadata": {},
   "source": [
    "Train validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3317b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import Callback\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee47b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CVE ID': 'CVE-2023-0002', 'Description': 'A problem with a protection mechanism in the Palo Alto Networks Cortex XDR agent on Windows devices allows a local user to execute privileged cytool commands that disable or uninstall the agent.\\n', 'CWE': ['NVD-CWE-Other'], 'cwe_class': 'CWE-Other'}\n"
     ]
    }
   ],
   "source": [
    "with open('cve_extracted_data2023_with_embeddings.pickle', 'rb') as f1:\n",
    "    input_file = pickle.load(f1)\n",
    "print(input_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1af945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1_weighted = 0.0\n",
    "        self.best_f1_macro = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores_weighted = []\n",
    "        self.f1_scores_macro = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1_weighted = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        f1_macro = f1_score(self.y_val, y_val_pred, average='macro')\n",
    "        \n",
    "        self.f1_scores_weighted.append(f1_weighted)\n",
    "        self.f1_scores_macro.append(f1_macro)\n",
    "        \n",
    "        if f1_weighted > self.best_f1_weighted:\n",
    "            self.best_f1_weighted = f1_weighted\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "            print(\"Saved best model (Weighted)\")\n",
    "        \n",
    "        if f1_macro > self.best_f1_macro:\n",
    "            self.best_f1_macro = f1_macro\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score (Macro): {f1_macro:.4f}\")\n",
    "            print(\"Saved best model (Macro)\")\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} - Weighted F1: {f1_weighted:.4f}, Macro F1: {f1_macro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f30a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed classes: Counter({'CWE-79': 136, 'CWE-89': 78, 'CWE-787': 42, 'CWE-416': 24, 'CWE-22': 20, 'CWE-94': 18, 'CWE-352': 18, 'CWE-77': 16, 'CWE-125': 13, 'CWE-476': 13, 'CWE-287': 12, 'CWE-862': 11, 'CWE-434': 11, 'CWE-404': 11, 'CWE-400': 8, 'CWE-863': 7, 'CWE-295': 7, 'CWE-78': 6, 'CWE-200': 6, 'CWE-20': 6, 'CWE-843': 6, 'CWE-319': 5, 'CWE-306': 5, 'CWE-119': 5, 'CWE-732': 5, 'CWE-427': 5, 'CWE-521': 5, 'CWE-120': 5, 'CWE-74': 4, 'CWE-601': 4, 'CWE-269': 4, 'CWE-190': 4, 'CWE-610': 3, 'CWE-294': 3, 'CWE-1021': 3, 'CWE-665': 3, 'CWE-502': 3, 'CWE-639': 3, 'CWE-312': 2, 'CWE-367': 2, 'CWE-613': 2, 'CWE-401': 2, 'CWE-203': 2, 'CWE-798': 2, 'CWE-428': 2, 'CWE-532': 2, 'CWE-668': 2, 'CWE-369': 2, 'CWE-770': 2, 'CWE-209': 2, 'CWE-311': 2, 'CWE-129': 2, 'CWE-667': 1, 'CWE-276': 1, 'CWE-681': 1, 'CWE-1284': 1, 'CWE-755': 1, 'CWE-327': 1, 'CWE-330': 1, 'CWE-345': 1, 'CWE-834': 1, 'CWE-835': 1, 'CWE-522': 1, 'CWE-763': 1, 'CWE-470': 1, 'CWE-326': 1, 'CWE-916': 1, 'CWE-754': 1, 'CWE-922': 1, 'CWE-1333': 1, 'CWE-88': 1, 'CWE-59': 1, 'CWE-362': 1, 'CWE-290': 1, 'CWE-193': 1, 'CWE-552': 1, 'CWE-459': 1, 'CWE-1321': 1, 'CWE-307': 1, 'CWE-611': 1, 'CWE-384': 1, 'CWE-346': 1, 'CWE-281': 1, 'CWE-415': 1, 'CWE-918': 1})\n",
      "423 423\n",
      "Data has been saved to train_val_test_split.pickle\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from collections import Counter\n",
    "# Filtering and creating the datasets\n",
    "train = np.array([item['embedding'] for item in input_file if 'embedding' in item])\n",
    "target = np.array([item['CWE'][0] for item in input_file if 'embedding' in item])\n",
    "\n",
    "counts = Counter(target)\n",
    "allowed_classes = {cls for cls, count in counts.items() if count >= 10}\n",
    "print(\"Allowed classes:\", counts)\n",
    "train_filtered = []\n",
    "target_filtered = []\n",
    "\n",
    "for emb, cls in zip(train, target):\n",
    "    if cls in allowed_classes:\n",
    "        train_filtered.append(emb)\n",
    "        target_filtered.append(cls)\n",
    "print(len(train_filtered), len(target_filtered))\n",
    "train_filtered = np.array(train_filtered)\n",
    "target_filtered = np.array(target_filtered)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    train_filtered, target_filtered, \n",
    "    test_size=0.3, random_state=42, stratify=target_filtered\n",
    ")\n",
    "\n",
    "\n",
    "# Splitting temp into validation and test sets with stratification\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Packing the data into a dictionary\n",
    "data_to_pickle = {\n",
    "    'X_train': X_train,\n",
    "    'X_val': X_val,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'y_test': y_test\n",
    "}\n",
    "\n",
    "# Saving to a pickle file\n",
    "pickle_file_path ='train_val_test_split.pickle'\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(data_to_pickle, f)\n",
    "\n",
    "print(f\"Data has been saved to {pickle_file_path}\")\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b4517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddfdf3",
   "metadata": {},
   "source": [
    "Train the model 3 times to ensure consistency of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68bd8855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 2.5691 - accuracy: 0.09\n",
      "Epoch 1 - F1 Score (Weighted): 0.2776\n",
      "Saved best model (Weighted)\n",
      "Epoch 1 - F1 Score (Macro): 0.0815\n",
      "Saved best model (Macro)\n",
      "Epoch 1 - Weighted F1: 0.2776, Macro F1: 0.0815\n",
      "10/10 [==============================] - 2s 91ms/step - loss: 2.2347 - accuracy: 0.3581 - val_loss: 1.9741 - val_accuracy: 0.4127\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.8724 - accuracy: 0.46\n",
      "Epoch 2 - F1 Score (Weighted): 0.3157\n",
      "Saved best model (Weighted)\n",
      "Epoch 2 - F1 Score (Macro): 0.1100\n",
      "Saved best model (Macro)\n",
      "Epoch 2 - Weighted F1: 0.3157, Macro F1: 0.1100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.8937 - accuracy: 0.4628 - val_loss: 1.8596 - val_accuracy: 0.4286\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.8485 - accuracy: 0.46\n",
      "Epoch 3 - Weighted F1: 0.3155, Macro F1: 0.1035\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7252 - accuracy: 0.4899 - val_loss: 1.7825 - val_accuracy: 0.4286\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.5805 - accuracy: 0.59\n",
      "Epoch 4 - F1 Score (Weighted): 0.3534\n",
      "Saved best model (Weighted)\n",
      "Epoch 4 - F1 Score (Macro): 0.1456\n",
      "Saved best model (Macro)\n",
      "Epoch 4 - Weighted F1: 0.3534, Macro F1: 0.1456\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5901 - accuracy: 0.5439 - val_loss: 1.6708 - val_accuracy: 0.4603\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.1167 - accuracy: 0.65\n",
      "Epoch 5 - Weighted F1: 0.3447, Macro F1: 0.1394\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4349 - accuracy: 0.5507 - val_loss: 1.6473 - val_accuracy: 0.4444\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.3773 - accuracy: 0.56\n",
      "Epoch 6 - F1 Score (Weighted): 0.3586\n",
      "Saved best model (Weighted)\n",
      "Epoch 6 - Weighted F1: 0.3586, Macro F1: 0.1424\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3438 - accuracy: 0.5743 - val_loss: 1.5318 - val_accuracy: 0.4603\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.3420 - accuracy: 0.53\n",
      "Epoch 7 - F1 Score (Weighted): 0.4040\n",
      "Saved best model (Weighted)\n",
      "Epoch 7 - F1 Score (Macro): 0.2233\n",
      "Saved best model (Macro)\n",
      "Epoch 7 - Weighted F1: 0.4040, Macro F1: 0.2233\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2609 - accuracy: 0.6014 - val_loss: 1.5013 - val_accuracy: 0.5079\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.1097 - accuracy: 0.65\n",
      "Epoch 8 - Weighted F1: 0.4024, Macro F1: 0.1875\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.1700 - accuracy: 0.5980 - val_loss: 1.4520 - val_accuracy: 0.4921\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.2224 - accuracy: 0.59\n",
      "Epoch 9 - F1 Score (Weighted): 0.4962\n",
      "Saved best model (Weighted)\n",
      "Epoch 9 - F1 Score (Macro): 0.2620\n",
      "Saved best model (Macro)\n",
      "Epoch 9 - Weighted F1: 0.4962, Macro F1: 0.2620\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0942 - accuracy: 0.6689 - val_loss: 1.4175 - val_accuracy: 0.6032\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.3107 - accuracy: 0.56\n",
      "Epoch 10 - Weighted F1: 0.4521, Macro F1: 0.2287\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0429 - accuracy: 0.6858 - val_loss: 1.3776 - val_accuracy: 0.5556\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.1675 - accuracy: 0.65\n",
      "Epoch 11 - F1 Score (Macro): 0.2680\n",
      "Saved best model (Macro)\n",
      "Epoch 11 - Weighted F1: 0.4638, Macro F1: 0.2680\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9821 - accuracy: 0.6824 - val_loss: 1.3448 - val_accuracy: 0.5556\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8432 - accuracy: 0.75\n",
      "Epoch 12 - F1 Score (Weighted): 0.5144\n",
      "Saved best model (Weighted)\n",
      "Epoch 12 - F1 Score (Macro): 0.3057\n",
      "Saved best model (Macro)\n",
      "Epoch 12 - Weighted F1: 0.5144, Macro F1: 0.3057\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9238 - accuracy: 0.7230 - val_loss: 1.3189 - val_accuracy: 0.6032\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.6022 - accuracy: 0.90\n",
      "Epoch 13 - F1 Score (Weighted): 0.5160\n",
      "Saved best model (Weighted)\n",
      "Epoch 13 - F1 Score (Macro): 0.3113\n",
      "Saved best model (Macro)\n",
      "Epoch 13 - Weighted F1: 0.5160, Macro F1: 0.3113\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8834 - accuracy: 0.7500 - val_loss: 1.2690 - val_accuracy: 0.6190\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8238 - accuracy: 0.75\n",
      "Epoch 14 - Weighted F1: 0.4923, Macro F1: 0.2897\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8103 - accuracy: 0.7601 - val_loss: 1.2665 - val_accuracy: 0.5873\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6350 - accuracy: 0.81\n",
      "Epoch 15 - Weighted F1: 0.4939, Macro F1: 0.2815\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7533 - accuracy: 0.7770 - val_loss: 1.2249 - val_accuracy: 0.5873\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8640 - accuracy: 0.68\n",
      "Epoch 16 - Weighted F1: 0.5066, Macro F1: 0.2985\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7221 - accuracy: 0.7973 - val_loss: 1.1948 - val_accuracy: 0.6032\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5286 - accuracy: 0.87\n",
      "Epoch 17 - Weighted F1: 0.5085, Macro F1: 0.2853\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6779 - accuracy: 0.8108 - val_loss: 1.1809 - val_accuracy: 0.6032\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5004 - accuracy: 0.87\n",
      "Epoch 18 - Weighted F1: 0.4920, Macro F1: 0.2796\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6480 - accuracy: 0.8176 - val_loss: 1.1882 - val_accuracy: 0.5873\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7597 - accuracy: 0.78\n",
      "Epoch 19 - F1 Score (Weighted): 0.5451\n",
      "Saved best model (Weighted)\n",
      "Epoch 19 - F1 Score (Macro): 0.3178\n",
      "Saved best model (Macro)\n",
      "Epoch 19 - Weighted F1: 0.5451, Macro F1: 0.3178\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6271 - accuracy: 0.8378 - val_loss: 1.1375 - val_accuracy: 0.6349\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4955 - accuracy: 0.93\n",
      "Epoch 20 - Weighted F1: 0.5387, Macro F1: 0.3083\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6022 - accuracy: 0.8345 - val_loss: 1.1470 - val_accuracy: 0.6349\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.5459 - accuracy: 0.90\n",
      "Epoch 21 - F1 Score (Weighted): 0.5742\n",
      "Saved best model (Weighted)\n",
      "Epoch 21 - F1 Score (Macro): 0.3791\n",
      "Saved best model (Macro)\n",
      "Epoch 21 - Weighted F1: 0.5742, Macro F1: 0.3791\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5551 - accuracy: 0.8547 - val_loss: 1.1188 - val_accuracy: 0.6508\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5337 - accuracy: 0.87\n",
      "Epoch 22 - Weighted F1: 0.5387, Macro F1: 0.3083\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5397 - accuracy: 0.8649 - val_loss: 1.0982 - val_accuracy: 0.6349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5065 - accuracy: 0.93\n",
      "Epoch 23 - Weighted F1: 0.5700, Macro F1: 0.3504\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5152 - accuracy: 0.8716 - val_loss: 1.0883 - val_accuracy: 0.6508\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.7320 - accuracy: 0.71\n",
      "Epoch 24 - Weighted F1: 0.5445, Macro F1: 0.2949\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4837 - accuracy: 0.8784 - val_loss: 1.0760 - val_accuracy: 0.6349\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5025 - accuracy: 0.90\n",
      "Epoch 25 - Weighted F1: 0.5643, Macro F1: 0.3420\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.8885 - val_loss: 1.0888 - val_accuracy: 0.6349\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.5312 - accuracy: 0.87\n",
      "Epoch 26 - Weighted F1: 0.5671, Macro F1: 0.3451\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4320 - accuracy: 0.9122 - val_loss: 1.0484 - val_accuracy: 0.6508\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3079 - accuracy: 0.93\n",
      "Epoch 27 - Weighted F1: 0.5731, Macro F1: 0.3506\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4144 - accuracy: 0.9122 - val_loss: 1.0248 - val_accuracy: 0.6508\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.4665 - accuracy: 0.93\n",
      "Epoch 28 - F1 Score (Weighted): 0.5895\n",
      "Saved best model (Weighted)\n",
      "Epoch 28 - Weighted F1: 0.5895, Macro F1: 0.3711\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3921 - accuracy: 0.9257 - val_loss: 1.0422 - val_accuracy: 0.6667\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3935 - accuracy: 0.90\n",
      "Epoch 29 - Weighted F1: 0.5865, Macro F1: 0.3652\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.9155 - val_loss: 1.0308 - val_accuracy: 0.6508\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3367 - accuracy: 0.96\n",
      "Epoch 30 - Weighted F1: 0.5715, Macro F1: 0.3259\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3638 - accuracy: 0.9426 - val_loss: 1.0212 - val_accuracy: 0.6508\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4718 - accuracy: 0.84\n",
      "Epoch 31 - Weighted F1: 0.5643, Macro F1: 0.2948\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3500 - accuracy: 0.9122 - val_loss: 0.9950 - val_accuracy: 0.6508\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3323 - accuracy: 0.93\n",
      "Epoch 32 - Weighted F1: 0.5783, Macro F1: 0.3557\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3353 - accuracy: 0.9324 - val_loss: 0.9846 - val_accuracy: 0.6508\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2998 - accuracy: 0.96\n",
      "Epoch 33 - F1 Score (Weighted): 0.6581\n",
      "Saved best model (Weighted)\n",
      "Epoch 33 - F1 Score (Macro): 0.4597\n",
      "Saved best model (Macro)\n",
      "Epoch 33 - Weighted F1: 0.6581, Macro F1: 0.4597\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3173 - accuracy: 0.9459 - val_loss: 0.9841 - val_accuracy: 0.7143\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2999 - accuracy: 1.00\n",
      "Epoch 34 - Weighted F1: 0.5652, Macro F1: 0.3164\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3050 - accuracy: 0.9358 - val_loss: 0.9624 - val_accuracy: 0.6508\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4006 - accuracy: 0.90\n",
      "Epoch 35 - Weighted F1: 0.6038, Macro F1: 0.3489\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2988 - accuracy: 0.9426 - val_loss: 0.9736 - val_accuracy: 0.6825\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.1460 - accuracy: 1.00\n",
      "Epoch 36 - Weighted F1: 0.6170, Macro F1: 0.4130\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2757 - accuracy: 0.9628 - val_loss: 0.9582 - val_accuracy: 0.6825\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3193 - accuracy: 0.93\n",
      "Epoch 37 - Weighted F1: 0.5908, Macro F1: 0.3543\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2733 - accuracy: 0.9392 - val_loss: 0.9538 - val_accuracy: 0.6667\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2467 - accuracy: 0.96\n",
      "Epoch 38 - Weighted F1: 0.6581, Macro F1: 0.4597\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2588 - accuracy: 0.9561 - val_loss: 0.9493 - val_accuracy: 0.7143\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2601 - accuracy: 0.93\n",
      "Epoch 39 - Weighted F1: 0.6375, Macro F1: 0.4015\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2485 - accuracy: 0.9527 - val_loss: 0.9547 - val_accuracy: 0.6984\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2005 - accuracy: 0.96\n",
      "Epoch 40 - Weighted F1: 0.6496, Macro F1: 0.4541\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2404 - accuracy: 0.9662 - val_loss: 0.9426 - val_accuracy: 0.6984\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 2.6800 - accuracy: 0.06\n",
      "Epoch 1 - F1 Score (Weighted): 0.2884\n",
      "Saved best model (Weighted)\n",
      "Epoch 1 - F1 Score (Macro): 0.0839\n",
      "Saved best model (Macro)\n",
      "Epoch 1 - Weighted F1: 0.2884, Macro F1: 0.0839\n",
      "10/10 [==============================] - 1s 26ms/step - loss: 2.2485 - accuracy: 0.3649 - val_loss: 2.0227 - val_accuracy: 0.4286\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.9972 - accuracy: 0.40\n",
      "Epoch 2 - F1 Score (Weighted): 0.3142\n",
      "Saved best model (Weighted)\n",
      "Epoch 2 - F1 Score (Macro): 0.1078\n",
      "Saved best model (Macro)\n",
      "Epoch 2 - Weighted F1: 0.3142, Macro F1: 0.1078\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.9091 - accuracy: 0.4696 - val_loss: 1.9046 - val_accuracy: 0.4286\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.5244 - accuracy: 0.65\n",
      "Epoch 3 - F1 Score (Weighted): 0.3263\n",
      "Saved best model (Weighted)\n",
      "Epoch 3 - F1 Score (Macro): 0.1110\n",
      "Saved best model (Macro)\n",
      "Epoch 3 - Weighted F1: 0.3263, Macro F1: 0.1110\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.7629 - accuracy: 0.4966 - val_loss: 1.7879 - val_accuracy: 0.4444\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.6601 - accuracy: 0.53\n",
      "Epoch 4 - Weighted F1: 0.3140, Macro F1: 0.1060\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6214 - accuracy: 0.5203 - val_loss: 1.7459 - val_accuracy: 0.4286\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.5369 - accuracy: 0.50\n",
      "Epoch 5 - F1 Score (Weighted): 0.3430\n",
      "Saved best model (Weighted)\n",
      "Epoch 5 - F1 Score (Macro): 0.1401\n",
      "Saved best model (Macro)\n",
      "Epoch 5 - Weighted F1: 0.3430, Macro F1: 0.1401\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.4906 - accuracy: 0.5338 - val_loss: 1.6730 - val_accuracy: 0.4444\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.5017 - accuracy: 0.50\n",
      "Epoch 6 - F1 Score (Weighted): 0.3529\n",
      "Saved best model (Weighted)\n",
      "Epoch 6 - F1 Score (Macro): 0.1465\n",
      "Saved best model (Macro)\n",
      "Epoch 6 - Weighted F1: 0.3529, Macro F1: 0.1465\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.3984 - accuracy: 0.5676 - val_loss: 1.5995 - val_accuracy: 0.4603\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.6015 - accuracy: 0.46\n",
      "Epoch 7 - Weighted F1: 0.3491, Macro F1: 0.1325\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.3046 - accuracy: 0.5743 - val_loss: 1.5775 - val_accuracy: 0.4444\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.0184 - accuracy: 0.68\n",
      "Epoch 8 - F1 Score (Weighted): 0.3722\n",
      "Saved best model (Weighted)\n",
      "Epoch 8 - F1 Score (Macro): 0.1514\n",
      "Saved best model (Macro)\n",
      "Epoch 8 - Weighted F1: 0.3722, Macro F1: 0.1514\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.2011 - accuracy: 0.5811 - val_loss: 1.4994 - val_accuracy: 0.4762\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.3162 - accuracy: 0.50\n",
      "Epoch 9 - F1 Score (Weighted): 0.3753\n",
      "Saved best model (Weighted)\n",
      "Epoch 9 - F1 Score (Macro): 0.1531\n",
      "Saved best model (Macro)\n",
      "Epoch 9 - Weighted F1: 0.3753, Macro F1: 0.1531\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1295 - accuracy: 0.6216 - val_loss: 1.4447 - val_accuracy: 0.4762\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.0273 - accuracy: 0.68\n",
      "Epoch 10 - F1 Score (Weighted): 0.3877\n",
      "Saved best model (Weighted)\n",
      "Epoch 10 - Weighted F1: 0.3877, Macro F1: 0.1464\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0476 - accuracy: 0.6588 - val_loss: 1.4207 - val_accuracy: 0.4762\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.0468 - accuracy: 0.68\n",
      "Epoch 11 - F1 Score (Weighted): 0.4224\n",
      "Saved best model (Weighted)\n",
      "Epoch 11 - F1 Score (Macro): 0.2089\n",
      "Saved best model (Macro)\n",
      "Epoch 11 - Weighted F1: 0.4224, Macro F1: 0.2089\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0072 - accuracy: 0.7027 - val_loss: 1.3983 - val_accuracy: 0.5079\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.9959 - accuracy: 0.65\n",
      "Epoch 12 - F1 Score (Weighted): 0.4577\n",
      "Saved best model (Weighted)\n",
      "Epoch 12 - F1 Score (Macro): 0.2269\n",
      "Saved best model (Macro)\n",
      "Epoch 12 - Weighted F1: 0.4577, Macro F1: 0.2269\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9395 - accuracy: 0.7331 - val_loss: 1.3418 - val_accuracy: 0.5556\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.0748 - accuracy: 0.62\n",
      "Epoch 13 - F1 Score (Weighted): 0.4630\n",
      "Saved best model (Weighted)\n",
      "Epoch 13 - F1 Score (Macro): 0.2388\n",
      "Saved best model (Macro)\n",
      "Epoch 13 - Weighted F1: 0.4630, Macro F1: 0.2388\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8646 - accuracy: 0.7230 - val_loss: 1.3054 - val_accuracy: 0.5556\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 1.0481 - accuracy: 0.62\n",
      "Epoch 14 - F1 Score (Weighted): 0.4680\n",
      "Saved best model (Weighted)\n",
      "Epoch 14 - F1 Score (Macro): 0.2486\n",
      "Saved best model (Macro)\n",
      "Epoch 14 - Weighted F1: 0.4680, Macro F1: 0.2486\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8277 - accuracy: 0.7601 - val_loss: 1.2853 - val_accuracy: 0.5714\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7864 - accuracy: 0.78\n",
      "Epoch 15 - F1 Score (Weighted): 0.4902\n",
      "Saved best model (Weighted)\n",
      "Epoch 15 - F1 Score (Macro): 0.2843\n",
      "Saved best model (Macro)\n",
      "Epoch 15 - Weighted F1: 0.4902, Macro F1: 0.2843\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7945 - accuracy: 0.7804 - val_loss: 1.2434 - val_accuracy: 0.5873\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7593 - accuracy: 0.71\n",
      "Epoch 16 - F1 Score (Weighted): 0.5511\n",
      "Saved best model (Weighted)\n",
      "Epoch 16 - F1 Score (Macro): 0.3239\n",
      "Saved best model (Macro)\n",
      "Epoch 16 - Weighted F1: 0.5511, Macro F1: 0.3239\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7475 - accuracy: 0.7905 - val_loss: 1.2585 - val_accuracy: 0.6508\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5092 - accuracy: 0.87\n",
      "Epoch 17 - Weighted F1: 0.5063, Macro F1: 0.2726\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7082 - accuracy: 0.8108 - val_loss: 1.2324 - val_accuracy: 0.5873\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6979 - accuracy: 0.90\n",
      "Epoch 18 - Weighted F1: 0.5336, Macro F1: 0.2772\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6639 - accuracy: 0.8378 - val_loss: 1.1755 - val_accuracy: 0.6349\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8115 - accuracy: 0.78\n",
      "Epoch 19 - Weighted F1: 0.5343, Macro F1: 0.2780\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6317 - accuracy: 0.8277 - val_loss: 1.1659 - val_accuracy: 0.6349\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4826 - accuracy: 0.87\n",
      "Epoch 20 - Weighted F1: 0.5164, Macro F1: 0.2995\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5944 - accuracy: 0.8378 - val_loss: 1.1572 - val_accuracy: 0.6032\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4764 - accuracy: 0.90\n",
      "Epoch 21 - Weighted F1: 0.5266, Macro F1: 0.2688\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5556 - accuracy: 0.8750 - val_loss: 1.1129 - val_accuracy: 0.6349\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6635 - accuracy: 0.84\n",
      "Epoch 22 - F1 Score (Weighted): 0.5602\n",
      "Saved best model (Weighted)\n",
      "Epoch 22 - F1 Score (Macro): 0.3260\n",
      "Saved best model (Macro)\n",
      "Epoch 22 - Weighted F1: 0.5602, Macro F1: 0.3260\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5397 - accuracy: 0.8953 - val_loss: 1.1147 - val_accuracy: 0.6508\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4045 - accuracy: 0.93\n",
      "Epoch 23 - Weighted F1: 0.5388, Macro F1: 0.2641\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5083 - accuracy: 0.8818 - val_loss: 1.1100 - val_accuracy: 0.6349\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5216 - accuracy: 0.84\n",
      "Epoch 24 - Weighted F1: 0.5376, Macro F1: 0.3041\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4997 - accuracy: 0.8818 - val_loss: 1.1155 - val_accuracy: 0.6349\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.6579 - accuracy: 0.78\n",
      "Epoch 25 - F1 Score (Weighted): 0.6010\n",
      "Saved best model (Weighted)\n",
      "Epoch 25 - F1 Score (Macro): 0.4339\n",
      "Saved best model (Macro)\n",
      "Epoch 25 - Weighted F1: 0.6010, Macro F1: 0.4339\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4890 - accuracy: 0.8581 - val_loss: 1.0984 - val_accuracy: 0.6508\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4942 - accuracy: 0.93\n",
      "Epoch 26 - Weighted F1: 0.5545, Macro F1: 0.3213\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4693 - accuracy: 0.8953 - val_loss: 1.1031 - val_accuracy: 0.6508\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4105 - accuracy: 0.96\n",
      "Epoch 27 - Weighted F1: 0.5961, Macro F1: 0.4221\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4420 - accuracy: 0.8986 - val_loss: 1.0771 - val_accuracy: 0.6508\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4268 - accuracy: 0.90\n",
      "Epoch 28 - Weighted F1: 0.5747, Macro F1: 0.3426\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.9088 - val_loss: 1.0927 - val_accuracy: 0.6508\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4868 - accuracy: 0.78\n",
      "Epoch 29 - F1 Score (Weighted): 0.6275\n",
      "Saved best model (Weighted)\n",
      "Epoch 29 - Weighted F1: 0.6275, Macro F1: 0.4237\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4047 - accuracy: 0.9189 - val_loss: 1.0491 - val_accuracy: 0.6825\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4498 - accuracy: 0.93\n",
      "Epoch 30 - F1 Score (Weighted): 0.6609\n",
      "Saved best model (Weighted)\n",
      "Epoch 30 - F1 Score (Macro): 0.4804\n",
      "Saved best model (Macro)\n",
      "Epoch 30 - Weighted F1: 0.6609, Macro F1: 0.4804\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.9324 - val_loss: 1.0365 - val_accuracy: 0.7143\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.4742 - accuracy: 0.96\n",
      "Epoch 31 - Weighted F1: 0.5864, Macro F1: 0.3460\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3620 - accuracy: 0.9358 - val_loss: 1.0562 - val_accuracy: 0.6667\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.3876 - accuracy: 0.81\n",
      "Epoch 32 - Weighted F1: 0.5948, Macro F1: 0.3467\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3600 - accuracy: 0.9426 - val_loss: 0.9985 - val_accuracy: 0.6667\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3030 - accuracy: 0.93\n",
      "Epoch 33 - Weighted F1: 0.5834, Macro F1: 0.3658\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3310 - accuracy: 0.9291 - val_loss: 1.0330 - val_accuracy: 0.6508\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2716 - accuracy: 0.93\n",
      "Epoch 34 - Weighted F1: 0.6434, Macro F1: 0.4487\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3237 - accuracy: 0.9257 - val_loss: 0.9996 - val_accuracy: 0.6984\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3025 - accuracy: 1.00\n",
      "Epoch 35 - Weighted F1: 0.6528, Macro F1: 0.4772\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3193 - accuracy: 0.9595 - val_loss: 1.0182 - val_accuracy: 0.7143\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2391 - accuracy: 0.96\n",
      "Epoch 36 - Weighted F1: 0.6396, Macro F1: 0.4329\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2985 - accuracy: 0.9493 - val_loss: 0.9919 - val_accuracy: 0.6984\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3165 - accuracy: 0.93\n",
      "Epoch 37 - Weighted F1: 0.6319, Macro F1: 0.4246\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2951 - accuracy: 0.9459 - val_loss: 0.9974 - val_accuracy: 0.6825\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3087 - accuracy: 0.93\n",
      "Epoch 38 - Weighted F1: 0.6511, Macro F1: 0.4686\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2844 - accuracy: 0.9696 - val_loss: 0.9979 - val_accuracy: 0.6984\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2668 - accuracy: 0.90\n",
      "Epoch 39 - F1 Score (Weighted): 0.6850\n",
      "Saved best model (Weighted)\n",
      "Epoch 39 - F1 Score (Macro): 0.5273\n",
      "Saved best model (Macro)\n",
      "Epoch 39 - Weighted F1: 0.6850, Macro F1: 0.5273\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2783 - accuracy: 0.9358 - val_loss: 1.0063 - val_accuracy: 0.7302\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2666 - accuracy: 0.96\n",
      "Epoch 40 - Weighted F1: 0.6273, Macro F1: 0.4279\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2596 - accuracy: 0.9595 - val_loss: 0.9757 - val_accuracy: 0.6825\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 2.6276 - accuracy: 0.09\n",
      "Epoch 1 - F1 Score (Weighted): 0.2628\n",
      "Saved best model (Weighted)\n",
      "Epoch 1 - F1 Score (Macro): 0.0726\n",
      "Saved best model (Macro)\n",
      "Epoch 1 - Weighted F1: 0.2628, Macro F1: 0.0726\n",
      "10/10 [==============================] - 1s 27ms/step - loss: 2.1629 - accuracy: 0.3547 - val_loss: 2.0114 - val_accuracy: 0.3810\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 2.1008 - accuracy: 0.34\n",
      "Epoch 2 - F1 Score (Weighted): 0.3380\n",
      "Saved best model (Weighted)\n",
      "Epoch 2 - F1 Score (Macro): 0.1146\n",
      "Saved best model (Macro)\n",
      "Epoch 2 - Weighted F1: 0.3380, Macro F1: 0.1146\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.8144 - accuracy: 0.4831 - val_loss: 1.7929 - val_accuracy: 0.4603\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.5925 - accuracy: 0.53\n",
      "Epoch 3 - F1 Score (Weighted): 0.3483\n",
      "Saved best model (Weighted)\n",
      "Epoch 3 - F1 Score (Macro): 0.1388\n",
      "Saved best model (Macro)\n",
      "Epoch 3 - Weighted F1: 0.3483, Macro F1: 0.1388\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.6448 - accuracy: 0.5270 - val_loss: 1.7339 - val_accuracy: 0.4444\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.6234 - accuracy: 0.53\n",
      "Epoch 4 - F1 Score (Weighted): 0.3511\n",
      "Saved best model (Weighted)\n",
      "Epoch 4 - F1 Score (Macro): 0.1398\n",
      "Saved best model (Macro)\n",
      "Epoch 4 - Weighted F1: 0.3511, Macro F1: 0.1398\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.4793 - accuracy: 0.5507 - val_loss: 1.6312 - val_accuracy: 0.4444\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.3220 - accuracy: 0.62\n",
      "Epoch 5 - F1 Score (Weighted): 0.3953\n",
      "Saved best model (Weighted)\n",
      "Epoch 5 - F1 Score (Macro): 0.1534\n",
      "Saved best model (Macro)\n",
      "Epoch 5 - Weighted F1: 0.3953, Macro F1: 0.1534\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3492 - accuracy: 0.5709 - val_loss: 1.5234 - val_accuracy: 0.5079\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 1.4642 - accuracy: 0.50\n",
      "Epoch 6 - F1 Score (Weighted): 0.4110\n",
      "Saved best model (Weighted)\n",
      "Epoch 6 - F1 Score (Macro): 0.2335\n",
      "Saved best model (Macro)\n",
      "Epoch 6 - Weighted F1: 0.4110, Macro F1: 0.2335\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.2643 - accuracy: 0.5980 - val_loss: 1.4709 - val_accuracy: 0.5079\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.9269 - accuracy: 0.75\n",
      "Epoch 7 - F1 Score (Weighted): 0.4525\n",
      "Saved best model (Weighted)\n",
      "Epoch 7 - F1 Score (Macro): 0.2554\n",
      "Saved best model (Macro)\n",
      "Epoch 7 - Weighted F1: 0.4525, Macro F1: 0.2554\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1722 - accuracy: 0.6149 - val_loss: 1.4240 - val_accuracy: 0.5397\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 1.1375 - accuracy: 0.62\n",
      "Epoch 8 - Weighted F1: 0.4151, Macro F1: 0.2220\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.1298 - accuracy: 0.6419 - val_loss: 1.4154 - val_accuracy: 0.5079\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.8915 - accuracy: 0.70\n",
      "Epoch 9 - F1 Score (Weighted): 0.5305\n",
      "Saved best model (Weighted)\n",
      "Epoch 9 - F1 Score (Macro): 0.2798\n",
      "Saved best model (Macro)\n",
      "Epoch 9 - Weighted F1: 0.5305, Macro F1: 0.2798\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.0290 - accuracy: 0.6554 - val_loss: 1.3063 - val_accuracy: 0.6349\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 4ms/step loss: 0.7548 - accuracy: 0.75\n",
      "Epoch 10 - Weighted F1: 0.4643, Macro F1: 0.2591\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9549 - accuracy: 0.6892 - val_loss: 1.3003 - val_accuracy: 0.5556\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7911 - accuracy: 0.75\n",
      "Epoch 11 - F1 Score (Weighted): 0.5498\n",
      "Saved best model (Weighted)\n",
      "Epoch 11 - F1 Score (Macro): 0.3283\n",
      "Saved best model (Macro)\n",
      "Epoch 11 - Weighted F1: 0.5498, Macro F1: 0.3283\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9146 - accuracy: 0.7264 - val_loss: 1.2545 - val_accuracy: 0.6508\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 5ms/step loss: 0.9511 - accuracy: 0.68\n",
      "Epoch 12 - Weighted F1: 0.4860, Macro F1: 0.2472\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8471 - accuracy: 0.7601 - val_loss: 1.2374 - val_accuracy: 0.5714\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8802 - accuracy: 0.75\n",
      "Epoch 13 - Weighted F1: 0.5300, Macro F1: 0.3064\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7843 - accuracy: 0.8108 - val_loss: 1.2274 - val_accuracy: 0.6349\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7873 - accuracy: 0.78\n",
      "Epoch 14 - Weighted F1: 0.5047, Macro F1: 0.2986\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7509 - accuracy: 0.7635 - val_loss: 1.2087 - val_accuracy: 0.5714\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.8494 - accuracy: 0.81\n",
      "Epoch 15 - F1 Score (Weighted): 0.5660\n",
      "Saved best model (Weighted)\n",
      "Epoch 15 - Weighted F1: 0.5660, Macro F1: 0.3278\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7048 - accuracy: 0.8108 - val_loss: 1.1631 - val_accuracy: 0.6667\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7187 - accuracy: 0.84\n",
      "Epoch 16 - Weighted F1: 0.5608, Macro F1: 0.3180\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6475 - accuracy: 0.8581 - val_loss: 1.1155 - val_accuracy: 0.6508\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.7831 - accuracy: 0.71\n",
      "Epoch 17 - F1 Score (Weighted): 0.5772\n",
      "Saved best model (Weighted)\n",
      "Epoch 17 - F1 Score (Macro): 0.3749\n",
      "Saved best model (Macro)\n",
      "Epoch 17 - Weighted F1: 0.5772, Macro F1: 0.3749\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6229 - accuracy: 0.8311 - val_loss: 1.1033 - val_accuracy: 0.6667\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.6964 - accuracy: 0.84\n",
      "Epoch 18 - Weighted F1: 0.5594, Macro F1: 0.3048\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5889 - accuracy: 0.8514 - val_loss: 1.0845 - val_accuracy: 0.6508\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5199 - accuracy: 0.93\n",
      "Epoch 19 - Weighted F1: 0.5490, Macro F1: 0.2951\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5674 - accuracy: 0.8784 - val_loss: 1.0838 - val_accuracy: 0.6508\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4032 - accuracy: 0.93\n",
      "Epoch 20 - Weighted F1: 0.5169, Macro F1: 0.2710\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5323 - accuracy: 0.8412 - val_loss: 1.1176 - val_accuracy: 0.5873\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5164 - accuracy: 0.87\n",
      "Epoch 21 - F1 Score (Weighted): 0.5910\n",
      "Saved best model (Weighted)\n",
      "Epoch 21 - Weighted F1: 0.5910, Macro F1: 0.3643\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5010 - accuracy: 0.8851 - val_loss: 1.0298 - val_accuracy: 0.6667\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3280 - accuracy: 0.93\n",
      "Epoch 22 - Weighted F1: 0.5670, Macro F1: 0.2933\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4645 - accuracy: 0.9088 - val_loss: 1.0204 - val_accuracy: 0.6508\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4553 - accuracy: 0.90\n",
      "Epoch 23 - Weighted F1: 0.5894, Macro F1: 0.3511\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4390 - accuracy: 0.9155 - val_loss: 1.0194 - val_accuracy: 0.6667\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4631 - accuracy: 0.87\n",
      "Epoch 24 - Weighted F1: 0.5686, Macro F1: 0.3043\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4254 - accuracy: 0.8953 - val_loss: 0.9958 - val_accuracy: 0.6508\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3627 - accuracy: 0.96\n",
      "Epoch 25 - Weighted F1: 0.5643, Macro F1: 0.2948\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4006 - accuracy: 0.9122 - val_loss: 1.0079 - val_accuracy: 0.6508\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.5152 - accuracy: 0.90\n",
      "Epoch 26 - F1 Score (Weighted): 0.6404\n",
      "Saved best model (Weighted)\n",
      "Epoch 26 - F1 Score (Macro): 0.4341\n",
      "Saved best model (Macro)\n",
      "Epoch 26 - Weighted F1: 0.6404, Macro F1: 0.4341\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.9257 - val_loss: 0.9789 - val_accuracy: 0.6984\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3346 - accuracy: 1.00\n",
      "Epoch 27 - Weighted F1: 0.5940, Macro F1: 0.3662\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3730 - accuracy: 0.9459 - val_loss: 0.9873 - val_accuracy: 0.6667\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.5214 - accuracy: 0.84\n",
      "Epoch 28 - Weighted F1: 0.6180, Macro F1: 0.3868\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.9291 - val_loss: 0.9585 - val_accuracy: 0.6825\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2547 - accuracy: 0.93\n",
      "Epoch 29 - F1 Score (Weighted): 0.6471\n",
      "Saved best model (Weighted)\n",
      "Epoch 29 - F1 Score (Macro): 0.4495\n",
      "Saved best model (Macro)\n",
      "Epoch 29 - Weighted F1: 0.6471, Macro F1: 0.4495\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3299 - accuracy: 0.9291 - val_loss: 0.9445 - val_accuracy: 0.6984\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2659 - accuracy: 1.00\n",
      "Epoch 30 - Weighted F1: 0.5925, Macro F1: 0.3730\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3249 - accuracy: 0.9595 - val_loss: 0.9754 - val_accuracy: 0.6667\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2370 - accuracy: 0.96\n",
      "Epoch 31 - Weighted F1: 0.6115, Macro F1: 0.4154\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3131 - accuracy: 0.9257 - val_loss: 0.9728 - val_accuracy: 0.6349\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.4385 - accuracy: 0.93\n",
      "Epoch 32 - Weighted F1: 0.5745, Macro F1: 0.3277\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2969 - accuracy: 0.9527 - val_loss: 0.9881 - val_accuracy: 0.6508\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.3080 - accuracy: 0.90\n",
      "Epoch 33 - Weighted F1: 0.6402, Macro F1: 0.3940\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2856 - accuracy: 0.9324 - val_loss: 0.9432 - val_accuracy: 0.6984\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.3247 - accuracy: 0.93\n",
      "Epoch 34 - Weighted F1: 0.6376, Macro F1: 0.4452\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2643 - accuracy: 0.9595 - val_loss: 0.9363 - val_accuracy: 0.6984\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2311 - accuracy: 0.96\n",
      "Epoch 35 - F1 Score (Weighted): 0.6709\n",
      "Saved best model (Weighted)\n",
      "Epoch 35 - F1 Score (Macro): 0.4916\n",
      "Saved best model (Macro)\n",
      "Epoch 35 - Weighted F1: 0.6709, Macro F1: 0.4916\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2548 - accuracy: 0.9628 - val_loss: 0.9144 - val_accuracy: 0.7143\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2395 - accuracy: 1.00\n",
      "Epoch 36 - Weighted F1: 0.6350, Macro F1: 0.3965\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2343 - accuracy: 0.9730 - val_loss: 0.9445 - val_accuracy: 0.6984\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2346 - accuracy: 0.93\n",
      "Epoch 37 - F1 Score (Weighted): 0.6827\n",
      "Saved best model (Weighted)\n",
      "Epoch 37 - F1 Score (Macro): 0.4973\n",
      "Saved best model (Macro)\n",
      "Epoch 37 - Weighted F1: 0.6827, Macro F1: 0.4973\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2325 - accuracy: 0.9595 - val_loss: 0.9121 - val_accuracy: 0.7302\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 3ms/step loss: 0.2702 - accuracy: 0.96\n",
      "Epoch 38 - Weighted F1: 0.6641, Macro F1: 0.4580\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2301 - accuracy: 0.9662 - val_loss: 0.9171 - val_accuracy: 0.7143\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 1ms/step loss: 0.1406 - accuracy: 1.00\n",
      "Epoch 39 - F1 Score (Weighted): 0.6832\n",
      "Saved best model (Weighted)\n",
      "Epoch 39 - F1 Score (Macro): 0.5035\n",
      "Saved best model (Macro)\n",
      "Epoch 39 - Weighted F1: 0.6832, Macro F1: 0.5035\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2112 - accuracy: 0.9764 - val_loss: 0.9118 - val_accuracy: 0.7143\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 2ms/step loss: 0.2245 - accuracy: 0.93\n",
      "Epoch 40 - Weighted F1: 0.6385, Macro F1: 0.4369\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2120 - accuracy: 0.9696 - val_loss: 0.9354 - val_accuracy: 0.6984\n",
      "Saved base model \n",
      "Saved base model \n",
      "Saved base model \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_descr.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "f1_scores_list = []  # To store scores for all models\n",
    "for i in range(3):\n",
    "    model = create_model(input_dim, output_dim)\n",
    "    f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "    model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, \n",
    "              validation_data=(X_val, label_encoder_train.transform(y_val)), \n",
    "              verbose=1, callbacks=[f1_callback])\n",
    "    models.append(model)\n",
    "    \n",
    "    # Save the F1 scores for this model\n",
    "    f1_scores = pd.DataFrame({\n",
    "        'Epoch': list(range(1, len(f1_callback.f1_scores_weighted) + 1)),\n",
    "        'Weighted F1': f1_callback.f1_scores_weighted,\n",
    "        'Macro F1': f1_callback.f1_scores_macro\n",
    "    })\n",
    "    f1_scores.to_csv(f'f1_scores_model_{i+1}.csv', index=False)\n",
    "    f1_scores_list.append(f1_scores)\n",
    "\n",
    "# Save the retrained models\n",
    "for i, model in enumerate(models):\n",
    "    model.save(f'/home/simonettos/cybersecurity_dataset/pseudo-learning/base_model{i}.h5')\n",
    "    print(f\"Saved base model \")\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_descr.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92aaa14",
   "metadata": {},
   "source": [
    "Average the performanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5ccc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Classification Report (Averaged Across Models):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CWE-125     0.0000    0.0000    0.0000         2\n",
      "      CWE-22     1.0000    0.3333    0.5000         3\n",
      "     CWE-287     0.0000    0.0000    0.0000         2\n",
      "     CWE-352     1.0000    1.0000    1.0000         2\n",
      "     CWE-404     0.5000    1.0000    0.6667         1\n",
      "     CWE-416     1.0000    1.0000    1.0000         4\n",
      "     CWE-434     0.0000    0.0000    0.0000         1\n",
      "     CWE-476     0.5000    0.5000    0.5000         2\n",
      "      CWE-77     1.0000    0.3333    0.5000         3\n",
      "     CWE-787     0.7000    1.0000    0.8235         7\n",
      "      CWE-79     0.8400    1.0000    0.9130        21\n",
      "     CWE-862     0.0000    0.0000    0.0000         1\n",
      "      CWE-89     0.9167    0.9167    0.9167        12\n",
      "      CWE-94     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.7969        64\n",
      "   macro avg     0.5802    0.5536    0.5348        64\n",
      "weighted avg     0.7662    0.7969    0.7595        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `models` contains all trained models\n",
    "y_val_encoded = label_encoder_train.transform(y_test)\n",
    "\n",
    "# Initialize an array to store the cumulative probabilities for averaging\n",
    "cumulative_probs = np.zeros((len(y_test), len(label_encoder_train.classes_)))\n",
    "\n",
    "for model in models:\n",
    "    # Predict probabilities with the current model\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    cumulative_probs += y_pred_probs  # Sum the probabilities for averaging\n",
    "\n",
    "# Average the probabilities across all models\n",
    "average_probs = cumulative_probs / len(models)\n",
    "\n",
    "# Get the final predictions by taking the class with the highest probability\n",
    "y_pred = np.argmax(average_probs, axis=1)\n",
    "\n",
    "# Decode the predicted labels to their original form\n",
    "y_pred_decoded = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report (Averaged Across Models):\")\n",
    "print(classification_report(y_test, y_pred_decoded, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
